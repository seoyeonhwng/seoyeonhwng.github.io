---
layout:     post
title:      "AWS S3란 무엇인가"
date:       2020-04-11 12:00:00
author:     "yellie"
header-style: text
tags:
    - AWS
    - S3
---
AWS 뿌시기 2탄은 람다 배포 패키징 포스팅에서 잠깐 언급된 S3이다.

AWS로 개발하다보면 S3는 필수 서비스라는 생각이 들었기 때문에 두번째 주제로 정해보았다. 사용법이 어렵지 않으니 한번 익혀두면 계속해서 유용하게 쓸 수 있을 것이다.

오늘은 S3가 무엇인지 간단하게 살펴본 후, python으로 S3를 간단하게 사용해보자!

## S3?
S3는 AWS에서 제공하는 **인터넷용 스토리지 서비스(=저장소)** 로, 원하는 양의 데이터를 저장, 검색, 삭제할 수 있다. 구글 드라이브와 비슷하다.

S3는 버킷(Bucket)과 키(Key)로 구성되어 있다.
- **버킷(Bucket)** : S3에 저장된 객체에 대한 컨테이너
- **키(Key)** : 버킷 내 객체의 고유한 **식별자**로 버킷 내 모든 객체는 정확히 하나의 키를 갖는다.

예를 들어, `data` 버킷에 키가 `photos/puppy.jpg` 인 파일을 저장할 수 있다.

*처음 S3를 공부할때 폴더 안에 폴더 라는 개념이 아니고 하나의 키라는 점이 조금 헷갈렸다.*

## 튜토리얼
S3에 버킷을 만들어보고 버킷에 csv 파일을 업로드, 다운로드, 삭제해보자!

1. AWS S3로 들어간다.
![image](https://user-images.githubusercontent.com/49056225/122343475-b424b480-cf80-11eb-8515-f9ae25dbd951.png)

2. 오른쪽 상단에 `버킷 만들기` 버튼을 누르고 버킷을 만든다.
![image](https://user-images.githubusercontent.com/49056225/122343564-cacb0b80-cf80-11eb-87dc-d6e727ff60ba.png)
![image](https://user-images.githubusercontent.com/49056225/122343593-d4547380-cf80-11eb-9a9a-57402af17d7f.png)

3. 파이썬 가상환경에 boto3를 설치한다.
```
pipenv install boto3
```

4. csv 파일을 업로드, 다운로드, 삭제해보자!
4-1) **upload**
```
def upload_file():
    s3 = boto3.resource('s3')
    
    local_path = 'customer.csv'
    bucket_name = 'seoyeon-test'
    key = '2020-04-11/customer.csv'
    
    s3.meta.client.upload_file(local_path, bucket_name, key)
```

- **local_path** : 업로드 하려는 파일의 로컬 경로
- **bucket_name** : 위에서 만든 버킷 이름
- **key** : 버킷 안에서 저장하고자 하는 경로

`seoyeon-test` 버킷에 `2020-04-11/customer.csv`파일을 저장했다.
![image](https://user-images.githubusercontent.com/49056225/122343789-0cf44d00-cf81-11eb-923d-1ccbafc3101c.png)

4-2) **download**
```
def download_data():
    s3 = boto3.resource('s3')
    
    bucket_name = 'seoyeon-test'
    key = '2020-04-11/customer.csv'
    download_path = 'data_from_s3.csv'
    
    bucket = s3.Bucket(bucket_name)
    objects = list(bucket.objects.filter(Prefix=key))
    
    if objects and objects[0].key == key:
        bucket.download_file(objects[0].key, download_path)
        return True
    return False
```

- **bucket_name** : 다운로드 하고자 하는 파일이 저장된 버킷 이름
- **key** : 다운로드 하고자 하는 파일이 저장된 버킷 안의 경로
- **download_path** : 다운로드한 파일 저장 경로

`seoyeon-test` 버킷에 저장된 `2020-04-11/customer.csv`파일을 다운로드 받아서 `data_from_s3.csv` 로 저장했다.
![image](https://user-images.githubusercontent.com/49056225/122343984-4331cc80-cf81-11eb-9e1c-d78216edce4d.png)

4-3) **delete**
```
def delete_file():
    s3 = boto3.resource('s3')
    
    bucket_name = 'seoyeon-test'
    key = '2020-04-11/customer.csv'
    s3.meta.client.delete_object(Bucket=bucket_name, Key=key)
```
- **bucket_name** : 삭제하고자 하는 파일이 저장된 버킷 이름
- **key** : 삭제하고자 하는 파일이 저장된 버킷 안의 경로

`seoyeon-test` 버킷에 저장된 `2020-04-11/customer.csv`파일을 삭제했다.
![image](https://user-images.githubusercontent.com/49056225/122344140-652b4f00-cf81-11eb-9961-c67b1f35bcf8.png)

회사에서는 아래 코드와 같이 S3Manager 클래스를 만들어 필요한 곳에 임포트해서 사용하고 있다.
<script src="https://gist.github.com/seoyeonhwng/89957716a5a3195cce82ac4b01422136.js"></script>

## 주의할 점
AWS Lambda는 파일을 /tmp/ 에 저장하기 때문에 **람다에서 S3에 접근하는 경우에는 local_path, download_path 앞에 /tmp/를 붙여줘야 한다.**
```
def upload_file(file_name):
    s3 = boto3.resource('s3')
    
    bucket_name = 'seoyeon-test'
    key = '2020-04-11/customer.csv'
    file_path = 'customer.csv' if IS_LOCAL else f'/tmp/customer.csv'
    
    s3.meta.client.upload_file(file_path, bucket_name, key)
```
